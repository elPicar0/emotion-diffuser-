
---

# ðŸ“ Project Architecture Documentation

## ðŸ”¹ backend/

### `main.py` â€” FastAPI entry point

**Purpose**

* Starts the API server
* Registers routes
* Defines global middleware later (CORS, logging, auth)

**Used by**

```
uvicorn backend.main:app --reload
```

---

### `routes.py` â€” API endpoints

**Purpose**

* Defines HTTP endpoints (`/analyze`, `/health`, `/feedback`, `/apologize`)
* Converts JSON â†’ Pydantic schema
* Calls orchestrator

**Never contains**

* ML logic
* prompt logic
* business rules

**Called automatically by**

```
backend.main
```

---

### `schemas.py` â€” JSON contracts

**Purpose**

* Defines input/output structures
* Ensures frontend/backend compatibility
* Enables FastAPI auto docs

**Example**

```
MessageIn
AnalysisOut
RewriteOut
ApologyOut
```

**Used by**

```
routes.py
tests/
frontend/
```

---

### `orchestrator.py` â€” system brain

**Purpose**

* Connects analysis engine + mediator engine
* Handles pipeline flow:

```
text â†’ analyze emotion â†’ check escalation â†’ rewrite â†’ generate apology â†’ return JSON
```

**This file controls the logic order of the system**

**Called by**

```
routes.py
```

---

### `config.py` â€” environment & settings

**Purpose**

* Loads API keys
* Stores model names
* Controls debug flags

**Typical contents**

```
OPENAI_API_KEY
MODEL_NAME
THRESHOLDS
```

**Loaded by**

```
mediator_engine/client.py
analysis_engine/models.py
```

---

# ðŸ”¹ analysis_engine/

### `analyzer.py` â€” emotion + escalation logic

**Purpose**

* Detect emotions
* Detect toxicity / aggression
* Score escalation level
* Return structured result

**Output example**

```
{
  "emotion": "anger",
  "intensity": 0.82,
  "risk": "high"
}
```

**Used by**

```
orchestrator.py
```

---

### `models.py` â€” model loading layer

**Purpose**

* Loads HuggingFace models
* Caches them for performance
* Abstracts model initialization

**Example responsibilities**

```
load_emotion_model()
load_toxicity_model()
```

**Used by**

```
analyzer.py
```

---

### `utils.py` â€” helper logic

**Purpose**

* Keyword triggers
* scoring normalization
* escalation thresholds
* text preprocessing

**Used by**

```
analyzer.py
```

---

# ðŸ”¹ mediator_engine/

### `rewrite.py` â€” LLM rewrite + apology logic

**Purpose**

* Takes emotional analysis + original text
* Requests LLM rewrite (tone softening)
* Generates heartfelt apology when escalation is detected
* Returns softened message + apology suggestion

**Output example (rewrite)**

```
{
  "rewritten": "...",
  "tone": "calm"
}
```

**Output example (apology)**

```
{
  "apology": "I realize what I said about ___ was hurtful. I take full responsibility...",
  "tone": "empathetic",
  "repair_type": "acknowledgment + ownership + repair"
}
```

**Used by**

```
orchestrator.py
```

---

### `prompts.py` â€” prompt definitions ONLY

**Purpose**

* Stores all system prompts (rewrite + apology)
* Stores few-shot examples for tone softening
* Stores few-shot examples for heartfelt apology generation
* Prevents prompt chaos across files

**This file should be the ONLY place containing prompts**

**Used by**

```
rewrite.py (both rewrite() and generate_apology())
```

---

### `client.py` â€” API wrapper

**Purpose**

* Handles OpenAI / Gemini / Claude calls
* Handles retries
* Handles rate limits
* Abstracts vendor switching

**Used by**

```
rewrite.py (rewrite + apology functions)
```

---

# ðŸ”¹ frontend/

### `app.py` â€” Streamlit UI

**Purpose**

* Text input box
* Displays analysis
* Displays rewritten output
* Displays heartfelt apology suggestion
* Calls backend API (`/analyze`, `/apologize`)

**Run with**

```
streamlit run frontend/app.py
```

---

# ðŸ”¹ datasets/

### `sample_dialogues.json`

**Purpose**

* Test conversations
* Demo inputs
* Fallback offline dataset

**Used by**

```
tests/
frontend demo mode
analysis benchmarking
```

---

# ðŸ”¹ tests/

### `test_analysis.py`

**Purpose**

* Tests emotion detection accuracy
* Ensures scoring consistency
* Prevents regression bugs

**Run with**

```
pytest tests/test_analysis.py
```

---

### `test_api.py`

**Purpose**

* Tests endpoints
* Ensures JSON format validity
* Ensures orchestrator works

**Run with**

```
pytest tests/test_api.py
```

---

# ðŸ”¹ Root files

### `requirements.txt`

**Purpose**

* Python dependencies
* Used for deployment

**Install with**

```
pip install -r requirements.txt
```

---

### `README.md`

**Purpose**

* Project explanation
* Setup instructions
* Architecture overview
* Demo instructions

---

# ðŸ§  How everything flows together

```
Frontend â†’ routes.py â†’ orchestrator.py
           â†“
      analyzer.py â†’ models.py â†’ utils.py
           â†“
      rewrite.py â†’ prompts.py â†’ client.py
           â†“                â†“
      calm rewrite    heartfelt apology
           â†“                â†“
         JSON response (merged)
```

**The system doesn't just de-escalate â€” it helps people repair relationships.**

Thatâ€™s your entire system lifecycle.

---

Perfect â€” this is exactly what judges *love* to see in a repo: clear ownership and modular responsibility.
Below is something you can paste straight into your **README â†’ Team Responsibilities** section.

---

# ðŸ‘¥ Team Responsibilities & File Ownership

To ensure parallel development and minimal merge conflicts, the project is divided into four independent modules.
Each teammate owns a subsystem and its corresponding files.

---

## ðŸ§  Member 1 â€” Backend & API Architect

**Role:** System entrypoint, API contracts, request routing
**Skill focus:** FastAPI, JSON design, architecture

### Files owned

```
backend/main.py
backend/routes.py
backend/schemas.py
backend/config.py
```

### Responsibilities

* Define API endpoints (`/analyze`, `/health`, `/rewrite`, `/apologize`)
* Define request/response schemas
* Handle validation & error handling
* Load environment variables and settings
* Ensure frontend can communicate with backend

### Deliverable

A working API server that accepts JSON and returns structured responses.

---

## ðŸ”¬ Member 2 â€” Emotion Analysis Engineer

**Role:** Emotion detection + escalation scoring
**Skill focus:** NLP, HuggingFace, Python logic

### Files owned

```
analysis_engine/analyzer.py
analysis_engine/models.py
analysis_engine/utils.py
```

### Responsibilities

* Load emotion & toxicity models
* Implement scoring logic
* Detect escalation triggers
* Output structured emotional analysis

### Deliverable

A function that converts raw text into emotion + risk scores.

---

## ðŸ•Šï¸ Member 3 â€” AI Mediation Engineer

**Role:** LLM rewriting + tone diffusion
**Skill focus:** LLM APIs, prompt design, output shaping

### Files owned

```
mediator_engine/rewrite.py
mediator_engine/prompts.py
mediator_engine/client.py
```

### Responsibilities

* Write system prompts for tone softening
* Write system prompts for heartfelt apology generation
* Integrate OpenAI/Gemini/Claude APIs
* Handle retries, formatting, token limits
* Produce calm, constructive rewrites
* Produce genuine, empathetic apologies that acknowledge + own + repair

### Deliverable

Two functions: one that converts emotional text into a calmer version, and one that generates a heartfelt apology.

---

## ðŸŽ¨ Member 4 â€” Frontend & Integration Engineer

**Role:** User interface + system integration testing
**Skill focus:** Streamlit, UX flow, API calls

### Files owned

```
frontend/app.py
datasets/sample_dialogues.json
tests/test_api.py
tests/test_analysis.py
README.md (demo section)
```

### Responsibilities

* Build user interface for message input/output
* Display emotion analysis visually
* Show rewritten suggestion
* Show heartfelt apology suggestion
* Write demo scripts & test cases
* Prepare demo walkthrough for judges

### Deliverable

A working interface that demonstrates the full pipeline.

---

# ðŸ§© Shared Responsibility

### `backend/orchestrator.py`

This file is the **integration layer**.

All members collaborate here to connect:

```
analysis_engine â†’ mediator_engine â†’ API output
```

No one edits this file alone â€” integration happens together near the end.

---

# ðŸš€ Development Strategy

Each member can work **independently** because:

* API contracts are defined early
* Engines return structured JSON
* Orchestrator connects modules only at final stage

This prevents blocking and enables parallel development.

---

If you want, I can also give you:

ðŸ‘‰ a **1-week hackathon timeline**
ðŸ‘‰ or a **Git workflow plan so merges donâ€™t explode**

Both massively increase your chances of actually finishing.

Perfect â€” now we go one level deeper.
Below is **member-by-member actionable instructions**. Not vague roles â€” actual â€œopen this file â†’ write this kind of codeâ€ guidance.

You can paste this into your README under **Implementation Guide**.

---

# ðŸ‘¨â€ðŸ’» Member 1 â€” Backend & API Architect

## `backend/main.py`

You must:

* Create FastAPI app instance
* Register router
* Add title + metadata
* Add root health endpoint

Goal:

```
uvicorn backend.main:app --reload
```

should start the server.

---

## `backend/routes.py`

You must:

* Define POST `/analyze`
* Define POST `/apologize`
* Accept `MessageIn` schema
* Call orchestrator function
* Return JSON response

Do NOT:

* Put ML code here
* Put prompts here

This file only routes requests.

---

## `backend/schemas.py`

You must:

* Define all API input/output formats

Minimum required schemas:

```
MessageIn(text: str)
AnalysisOut(emotion, intensity, risk)
RewriteOut(original, rewritten, emotion)
ApologyOut(original, apology, tone, repair_type)
```

This ensures the whole team speaks the same JSON language.

---

## `backend/config.py`

You must:

* Load environment variables
* Store model names
* Store API keys

Example responsibilities:

```
load OPENAI_API_KEY
set MODEL_NAME
define DEBUG flag
```

This file prevents keys scattered across project.

---

# ðŸ”¬ Member 2 â€” Emotion Analysis Engineer

## `analysis_engine/models.py`

You must:

* Load HuggingFace pipelines
* Cache them globally

Example tasks:

```
emotion_model = pipeline("text-classification", ...)
toxicity_model = pipeline(...)
```

This file only loads models â€” no logic.

---

## `analysis_engine/utils.py`

You must:

* Write helper logic

Examples:

* keyword triggers
* escalation thresholds
* normalization functions
* scoring adjustments

This file keeps analyzer clean.

---

## `analysis_engine/analyzer.py`

You must:

* Call models
* Interpret outputs
* Combine scores
* Produce structured JSON

Required output format:

```
{
  "emotion": "...",
  "intensity": float,
  "risk": "low/medium/high"
}
```

This file converts raw text â†’ emotional insight.

---

# ðŸ•Šï¸ Member 3 â€” AI Mediation Engineer

## `mediator_engine/prompts.py`

You must:

* Write all system prompts (rewrite + apology)
* Include few-shot examples for tone softening
* Include few-shot examples for heartfelt apologies
* Define tone rules
* Define apology structure: acknowledgment â†’ ownership â†’ repair offer

Nothing else in project should contain prompts.

This makes prompts editable without touching code.

---

## `mediator_engine/client.py`

You must:

* Implement API wrapper for LLM provider
* Load API key from config
* Handle retries/timeouts
* Return clean string output

This file isolates vendor lock-in.

---

## `mediator_engine/rewrite.py`

You must:

* Implement `rewrite()` â€” accepts original text + analysis, returns calm rewrite
* Implement `generate_apology()` â€” accepts original text + analysis, returns heartfelt apology
* Build final prompt using prompts.py
* Call client.py

Required output format (rewrite):

```
{
  "rewritten": "...",
  "tone": "calm"
}
```

Required output format (apology):

```
{
  "apology": "I realize that what I said was hurtful. I take responsibility for...",
  "tone": "empathetic",
  "repair_type": "acknowledgment + ownership + repair"
}
```

This file performs the actual mediation AND relationship repair.

---

# ðŸŽ¨ Member 4 â€” Frontend & Integration Engineer

## `frontend/app.py`

You must:

* Create text input box
* Send POST request to backend
* Display emotion analysis
* Display rewritten suggestion

Minimum demo flow:

```
User types message â†’ clicks button â†’ sees calm rewrite + heartfelt apology
```

Use Streamlit for speed.

Run with:

```
streamlit run frontend/app.py
```

---

## `datasets/sample_dialogues.json`

You must:

* Add sample arguments
* Add angry conversations
* Add neutral cases
* Add conflict escalation examples

These will be used for demo/testing.

---

## `tests/test_api.py`

You must:

* Test API endpoint works
* Test JSON schema valid
* Test server response time

Run with:

```
pytest tests/test_api.py
```

---

## `tests/test_analysis.py`

You must:

* Feed sample dialogues to analyzer
* Verify emotion labels reasonable
* Ensure risk scoring consistent

Run with:

```
pytest tests/test_analysis.py
```

---

# ðŸ§© ALL MEMBERS â€” Integration Phase

## `backend/orchestrator.py`

This file connects everything.

Final pipeline must be:

```
1. Receive text
2. Call analyzer
3. Call rewrite engine (tone softening)
4. Call apology engine (heartfelt apology generation)
5. Merge outputs
6. Return final JSON
```

No one writes this fully alone.

This file is built together once modules are ready.

---

# ðŸ’› Core Philosophy: Relationship Repair

This project doesn't just de-escalate conflict â€” it helps people **repair relationships**.

The heartfelt apology engine is what separates Emotion Diffuser from a simple tone-fixer.

Our apology system follows **established psychological models of apology effectiveness** â€” not just polite text generation.

---

# ðŸ§  The 5 Components of a Real Apology (Research-Backed)

## 1ï¸âƒ£ Acknowledgment of harm

You must show you understand what you did wrong.

âŒ "Sorry if you felt hurt."
âœ… "I shouldn't have dismissed your idea during the meeting."

**Why it matters:** People want to feel *seen*, not brushed off.

---

## 2ï¸âƒ£ Taking responsibility

No excuses. No blame shifting.

âŒ "I was stressed."
âŒ "You misunderstood me."
âœ… "That was my mistake."

**Why it matters:** Responsibility signals maturity and trustworthiness.

---

## 3ï¸âƒ£ Expression of remorse

Show genuine regret.

âŒ robotic: "I apologize."
âœ… human: "I feel bad about how I handled that."

**Why it matters:** Emotion signals sincerity.

---

## 4ï¸âƒ£ Repair / corrective intent

What will you do differently?

âŒ missing step â†’ apology feels empty
âœ… "Next time I'll check with you before making changes."

**Why it matters:** People forgive when they see future change.

---

## 5ï¸âƒ£ Invitation to respond (optional)

Gives the other person agency.

> "I understand if you're still upset, but I'd like to make this right."

**Why it matters:** Conflict resolution is two-sided.

---

# ðŸ§© LLM Apology Template

The AI must generate apologies following this structure:

```
1. Name the specific action
2. Accept responsibility
3. Express genuine regret
4. Offer repair / corrective change
5. Invite response (optional)
```

This template is enforced via `mediator_engine/prompts.py`.

---

# ðŸ¤– Example Transformation

### Input

> "I ignored my teammate's message because I was annoyed."

### AI Apology Output

> I realize I ignored your message earlier, and that wasn't fair to you.
> That was my mistake, and I shouldn't have let my frustration affect how I responded.
> I'm sorry for making you feel dismissed.
> I'll make sure to communicate properly even when I'm stressed.
> If you want to talk about it, I'm here.

**That feels human, not robotic.**

---

# ðŸ† Hackathon Pitch Angle

You can literally say to judges:

> "Our system follows established psychological models of apology effectiveness rather than just generating polite text."

That sounds **research-driven**, not gimmicky.

---

# ðŸ”„ Conversation Triggers: Re-Engagement System (Research-Backed)

When a conversation dies, relationships drift. Emotion Diffuser doesn't just fix *conflict* â€” it also fixes *silence*.

The system detects when a conversation is losing momentum and suggests **psychologically-grounded triggers** to re-engage.

---

## ðŸš¨ Disengagement Detection Signals

The analysis engine detects conversational fade-out by looking for:

| Signal | Example | Psychology |
|--------|---------|------------|
| **Short responses** | "ok", "yeah", "cool", "hmm" | Low cognitive investment = low interest |
| **Delayed replies** | Response time increasing | Approach-avoidance motivation (Elliot, 2006) |
| **No questions asked** | All statements, no curiosity | Lack of reciprocal engagement |
| **Flat emotional tone** | No humor, excitement, or warmth | Emotional disengagement (Gottman) |
| **Conversation loops** | Repeating same topic without depth | Topic exhaustion |

When **2+ signals** are detected, the system flags the conversation as **disengaging** and offers re-engagement triggers.

---

## ðŸ§  5 Re-Engagement Strategies (Psychology-Backed)

### 1ï¸âƒ£ The Curiosity Gap

**Based on:** Loewenstein's Information Gap Theory (1994)

Create a gap between what someone knows and what they *want* to know.

âŒ "How was your day?"
âœ… "Something wild happened today â€” remind me to tell you later."

**Why it works:** The brain craves closure. An open loop compels a response.

---

### 2ï¸âƒ£ The Reciprocity Hook

**Based on:** Cialdini's Principle of Reciprocity (1984)

Share something personal first â€” people feel compelled to match your vulnerability.

âŒ "What are you thinking about?"
âœ… "I've been overthinking something all dayâ€¦ can I get your take?"

**Why it works:** Vulnerability invites vulnerability. Giving first triggers giving back.

---

### 3ï¸âƒ£ The Self-Disclosure Ladder

**Based on:** Jourard's Self-Disclosure Theory (1971)

Gradually deepen the conversation by sharing something slightly more personal.

âŒ Surface: "Nice weather today."
âœ… Deeper: "I've been thinking about whether I'm actually happy with how things are going."

**Why it works:** Relationships deepen through progressive self-disclosure. Staying surface-level kills connection.

---

### 4ï¸âƒ£ The Open-Ended Pivot

**Based on:** Motivational Interviewing (Miller & Rollnick, 2002)

Replace closed questions with open ones that invite storytelling.

âŒ "Did you like the movie?" â†’ "yeah"
âœ… "What part of the movie stuck with you?" â†’ actual conversation

**Why it works:** Open questions activate narrative thinking, which produces longer, richer responses.

---

### 5ï¸âƒ£ The Validation Anchor

**Based on:** Emotional Validation Theory (Linehan, 1993)

Acknowledge what someone just said before pivoting.

âŒ Ignoring their last message and changing topic
âœ… "That makes total sense â€” and it reminds me of somethingâ€¦"

**Why it works:** People disengage when they feel unheard. Validation reopens the door.

---

## ðŸ§© Trigger Detection Output Format

```
{
  "engagement_level": "low",
  "signals_detected": ["short_responses", "no_questions"],
  "suggested_trigger": {
    "strategy": "curiosity_gap",
    "suggestion": "Something came up today that I think you'd find interesting...",
    "psychology": "Loewenstein's Information Gap Theory"
  }
}
```

This is produced by `analysis_engine/analyzer.py` and surfaced via `orchestrator.py`.

---

## ðŸ¤– Example Transformation

### Input (dying conversation)

```
Person A: "Hey"
Person B: "Hey"
Person A: "What's up"
Person B: "Nothing much"
Person A: "Cool"
```

### System Detection

> âš ï¸ Engagement level: LOW â€” short responses, no questions, flat tone

### Suggested Trigger (Curiosity Gap)

> "I just found out something about [shared interest] that completely changed how I think about it â€” have you heard about this?"

### Suggested Trigger (Reciprocity Hook)

> "I've been meaning to ask you something â€” you're honestly the only person whose opinion I trust on this."

---

## ðŸ—ï¸ Pipeline Integration

```
1. Receive conversation history
2. Analyze engagement signals (analyzer.py)
3. If engagement = low â†’ generate re-engagement trigger
4. Select strategy based on conversation context
5. Return trigger suggestion via /triggers endpoint
```

**New endpoint:** `POST /triggers`
**New schema:** `TriggerOut(engagement_level, signals_detected, suggested_trigger)`

---

> **This is the heart of the project. De-escalation saves the moment. Apologies save the relationship. Triggers keep it alive.**

---

